# Telegram Bot PRD

## Project Overview
A Telegram bot that integrates with a local Ollama LLM (using Gemma 3:4b model) to provide intelligent responses when directly mentioned (@) in private chats and authorized group chats.

## Core Features
1. **Message Listening**
   - ✅ Bot responds only when directly mentioned using @
   - ✅ Works in private chats with the owner
   - ✅ Works in authorized group chats
   - ✅ Ignores messages where it's not directly mentioned

2. **User Authorization**
   - ✅ Primary user (owner) access control
   - ✅ Group chat authorization system
   - ✅ Whitelist-based access control

3. **LLM Integration**
   - ✅ Integration with local Ollama LLM using Gemma 3:4b model
   - ✅ Message context preservation
   - ✅ Conversation history tracking

4. **Context Management**
   - ✅ Maintains conversation history
   - ✅ Configurable context window size (default: 10 messages)
   - ✅ Manual history clearing via /clear command

## Technical Requirements
1. **Development Environment**
   - ✅ Local development setup
   - ✅ Python-based implementation
   - ✅ Telegram Bot API integration
   - ✅ Ollama API integration with Gemma 3:4b model

2. **Dependencies**
   - ✅ python-telegram-bot library
   - ✅ Ollama client library
   - ✅ Environment configuration management

3. **Security**
   - ✅ Bot token management
   - ✅ User authorization system
   - ✅ Group chat whitelist

## Implementation Phases

### Phase 1: Basic Setup
- [x] Set up development environment
- [x] Create Telegram bot and obtain token
- [x] Implement basic bot structure
- [x] Set up local Ollama connection with Gemma 3:4b model

### Phase 2: Core Functionality
- [x] Implement message listening
- [x] Add @ mention detection
- [x] Set up user authorization
- [x] Implement basic LLM integration with Gemma 3:4b

### Phase 3: Context Management
- [x] Implement conversation history tracking
- [x] Add context window management
- [x] Add manual history clearing

### Phase 4: Testing & Deployment
- [x] Local testing
  - [x] Authorization tests
  - [x] Context management tests
- [ ] User authorization testing in production
- [ ] Performance optimization
- [ ] Documentation

## Future Enhancements
1. Message rate limiting
2. Customizable context window size
3. Multiple LLM model support
4. Response formatting options
5. Error handling and logging
6. Remote deployment options

## Success Metrics
1. Response accuracy
2. Response time
3. Context preservation effectiveness
4. User satisfaction
5. System stability

## Notes
- Initial focus on local development
- Prioritize security and access control
- Maintain conversation context for better responses
- Regular testing and optimization required
- Uses Gemma 3:4b model through Ollama
- Context window size configurable via environment variables
